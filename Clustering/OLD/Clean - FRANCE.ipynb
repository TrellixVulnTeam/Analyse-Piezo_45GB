{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf0eb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "# Essential Libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "# Algorithms\n",
    "from minisom import MiniSom\n",
    "from tslearn.barycenters import dtw_barycenter_averaging\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix, r2_score\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "import matplotlib.dates as mdates\n",
    "import warnings\n",
    "\n",
    "# Suppression warnings pour calcul np sur des NaN\n",
    "warnings.filterwarnings(action='ignore', message='All-NaN slice encountered')\n",
    "\n",
    "# Liste des fonctions utilisées\n",
    "\n",
    "# Fonction de requetage auprès de la base de données sqlite\n",
    "def f_requete_sql (requete) :\n",
    "    try:\n",
    "        connexion = sqlite3.connect('../data/liste_piezos.db')\n",
    "        curseur = connexion.cursor()\n",
    "        print(\"Connexion réussie à SQLite\")\n",
    "        curseur.execute(requete)\n",
    "        connexion.commit()\n",
    "        resultat = curseur.fetchall()\n",
    "        curseur.close()\n",
    "        connexion.close()\n",
    "        print(\"Connexion SQLite est fermée\")\n",
    "        return resultat\n",
    "    except sqlite3.Error as error:\n",
    "        print(\"Erreur lors du mis à jour dans la table\", error)\n",
    "\n",
    "# Fonction d'affichage des valeurs manquantes\n",
    "def f_plot_nan (dataframe):\n",
    "    f, ax = plt.subplots(nrows=1, ncols=1, figsize=(16,6))\n",
    "    sns.heatmap(dataframe.T.isna(), cmap='Blues', cbar=False)\n",
    "    ax.set_title('Missing Values', fontsize=16)\n",
    "    # Masquage des noms de piezo \n",
    "    ax.yaxis.set_visible(False)\n",
    "    # Formatage de la date pour l'affichage\n",
    "    ax.xaxis.set_ticklabels([pd.to_datetime(value).strftime('%Y') for value in ax.xaxis.get_major_formatter().func.args[0].values()])\n",
    "    plt.show()\n",
    "        \n",
    "\n",
    "# Fonction pour standardiser les données\n",
    "def scaleColumns(df):\n",
    "    for col in df.columns:\n",
    "        df[col] = pd.DataFrame(scaler.fit_transform(pd.DataFrame(df[col])),columns=[col], index=df.index)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Sélection de la France entière\n",
    "regions = [\"FRANCE\"]\n",
    "\n",
    "\n",
    "print(\"Récupération des codes_bss où il y a un fichier piezo\")\n",
    "\n",
    "requete = f\"\"\"\n",
    "        SELECT code_bss\n",
    "        FROM data_piezo\n",
    "        WHERE cluster_kmeans IS NOT NULL\n",
    "         \"\"\"\n",
    "\n",
    "data = f_requete_sql(requete)\n",
    "code_bss = []\n",
    "for code in data:\n",
    "    code_bss.append(code[0]) \n",
    "\n",
    "\n",
    "print(f\"Récupération des {len(code_bss)} chroniques piezzo\")\n",
    "# Lecture des données du premier piezo de la liste pour initialiser le dataframe\n",
    "\n",
    "directory = '../data/piezo/'\n",
    "data = pd.read_csv(directory+f\"{code_bss[0]}.csv\", sep=\";\",  index_col=0, parse_dates=True)\n",
    "# ‘epoch’: origin is 1970-01-01\n",
    "data = data.resample('7D', origin =\"epoch\").mean()    \n",
    "data.rename(columns={\"piezo\":f\"{code_bss[0]}\"}, inplace=True)\n",
    "# Prise des données depuis 1980\n",
    "\n",
    "custom_date_parser = lambda x: datetime.strptime(x, \"%Y-%m-%d\")\n",
    "\n",
    "for file in code_bss[1:]:\n",
    "    df = pd.read_csv(f\"{directory+file}.csv\", sep=\";\",  index_col=0, parse_dates=True, date_parser=custom_date_parser)\n",
    "    df = df.resample('7D', origin =\"epoch\").mean()\n",
    "    df.rename(columns={\"piezo\":f\"{file}\"}, inplace=True)\n",
    "    data = pd.merge(data,df,left_index=True, right_index=True,how='outer')\n",
    "\n",
    "print(\"Traitement des données\")\n",
    "\n",
    "\n",
    "# Ajustement des dates de début et de fin\n",
    "# La plage de temps minimale est fixée à 8 ans. \n",
    "# La date de début et de fin correspondent à des dates où un maximum de piezos n'ont pas de valeur manquante.\n",
    "num_years = 0.0\n",
    "pourcentage_NaN = 0.0\n",
    "\n",
    "# Minimum de 8 ans d'intervalle\n",
    "# Si une date n'est pas calculable, num_years sera égal à NaN et la boucle s'arrête, ce qui n'est pas bon.\n",
    "    # Comme NaN n'est jamais égal à NaN, la condition d'arrêt n'est pas bonne si num_years n'est égal elle même et possède donc une valeur\n",
    "\n",
    "while num_years < 8 or num_years != num_years :\n",
    "    pourcentage_NaN += 0.01\n",
    "    date_init = data[(data.isnull().sum(axis=1)/data.shape[1] < pourcentage_NaN) == True].index.min()\n",
    "    date_fin = data[(data.isnull().sum(axis=1)/data.shape[1] < pourcentage_NaN) == True].index.max()\n",
    "    num_years = (date_fin - date_init).days / 365.2425\n",
    "\n",
    "print(f\"{int(100*(1-pourcentage_NaN))}% des chroniques ont été conservées pour plage de 8 ans.\")\n",
    "print(f\"Date de début : {date_init.strftime('%Y-%m-%d')}.\")\n",
    "print(f\"Date de fin : {date_fin.strftime('%Y-%m-%d')}.\")\n",
    "\n",
    "data_week_from_ = data.loc[date_init:date_fin]\n",
    "\n",
    "# Suppression des valeurs abérantes\n",
    "# Utilisation de la méthode IQR pour supprimer les valeurs abbérantes.\n",
    "# - Calcul des quartiles et de l'écart interquartile\n",
    "# - Suppression des valeurs < Q1 - 1.5*IQR\n",
    "# - Suppression des valeurs > Q3 + 1.5*IQR\n",
    "\n",
    "data_wo_outliers = data_week_from_.copy()\n",
    "for piezo in data_wo_outliers.columns : \n",
    "    q1 = np.nanquantile(data_wo_outliers[f\"{piezo}\"], .25)\n",
    "    q3 = np.nanquantile(data_wo_outliers[f\"{piezo}\"], .75)\n",
    "    IQR = q3-q1\n",
    "    data_wo_outliers.loc[data_wo_outliers[f\"{piezo}\"] < (q1-1.5*IQR), piezo] = np.NaN\n",
    "    data_wo_outliers.loc[data_wo_outliers[f\"{piezo}\"] > (q3+1.5*IQR), piezo] = np.NaN\n",
    "\n",
    "# Suppression des piezos avec plus de 10 valeurs manquantes consécutives\n",
    "max_consec_nan = 10\n",
    "bss_to_drop = []\n",
    "\n",
    "for piezo in data_wo_outliers :\n",
    "    compteur = 0\n",
    "    for date in data_wo_outliers.index :\n",
    "        if pd.isnull(data_wo_outliers.loc[date,piezo]):\n",
    "            compteur += 1\n",
    "        else : compteur = 0\n",
    "        if compteur == max_consec_nan:\n",
    "            bss_to_drop.append(piezo)\n",
    "            break\n",
    "\n",
    "data_clean = data_wo_outliers.copy().drop(bss_to_drop, axis=1)\n",
    "print(f\"Il reste {data_clean.shape[1]} chroniques avec suffisamment de données.\")\n",
    "\n",
    "\n",
    "# Interpolation linéaire pour les données manquantes\n",
    "data_interpol = data_clean.copy().interpolate('linear')\n",
    "\n",
    "# Réajustement des dates de début et de fin\n",
    "debut = []\n",
    "fin = []\n",
    "for column in data_interpol.columns:\n",
    "    debut.append(data_interpol[f\"{column}\"].first_valid_index())\n",
    "    fin.append(data_interpol[f\"{column}\"].last_valid_index()) \n",
    "# date_debut = plus grande date en partant du début où il n'y a plus de Nan. Inversement pour date_fin    \n",
    "date_debut = max(debut)\n",
    "date_fin = min(fin)\n",
    "data_interpol = data_interpol.loc[date_debut:date_fin]\n",
    "print(f\"Nombre total de Nan : {data_interpol.isna().sum().sum()}\")\n",
    "print(f\"Il y a {data_interpol.shape[1]} chroniques pour le clustering.\")\n",
    "\n",
    "\n",
    "# Normalisation StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data_norm = scaleColumns(data_interpol.copy())\n",
    "\n",
    "# Sauvegarde du dataframe traité en format csv en vue du clustering\n",
    "data_norm.to_csv(\"../Clustering/data/FRANCE.csv\", sep = \";\")\n",
    "print(\"dataframe enregistré en csv.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f8ee71e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe enregistré en csv.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15993747",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349.047px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "695.838px",
    "left": "1292.99px",
    "right": "20px",
    "top": "121px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
